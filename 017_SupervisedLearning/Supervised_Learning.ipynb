{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/RiverGumSecurity/AILabs/blob/main/017_SupervisedLearning/Supervised_Learning.ipynb\" target=\"_new\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning with Phishing Email Data\n",
    "\n",
    "This notebook explores core concepts and and provides examples of machine learning.  We will use phishing emails as a dataset and compare statistcal learning methods, such as Logistic Regression, Support Vector Machines, Decision Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import os \n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,f1_score,classification_report,ConfusionMatrixDisplay,confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect GPU device\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset that will be used to train and test the different models was from https://www.kaggle.com/datasets/subhajournal/phishingemails.  It was pre-labeled as \"Safe Email\" or \"Phishing Email\".  The data will be cleaned and prepared for training machine learning models with Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data into a Pandas dataframe\n",
    "#df = pd.read_csv('../datasets/Phishing_Email.csv')\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/RiverGumSecurity/Datasets/refs/heads/main/Kaggle/Phishing_Email.csv.gz')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information on the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find null values in the data - these can cause issues for computation later in the notebook\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values in place, drop Unamed:0 column, drop duplicates\n",
    "df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df.dropna(inplace=True,axis=0)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the count of Email types, a Safe Email or a Phishing Email\n",
    "df['Email Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot counts of Safe Email vs Phishing Email\n",
    "df['Email Type'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to further process and clean the data. This is a binary classification problem, and we need to assign a label (a 1 or a 0) to the email categories. Then we will remove URLS and non word characters from the emails - we are interested in the similarities of the text itself.  Then we lowercase all of the characters, convert all multiple whitespace characters to single whitespace, and remove any trailing whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Email Type\n",
    "lbl = LabelEncoder()\n",
    "df['Email Type'] = lbl.fit_transform(df['Email Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text.\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "df['Email Text']=df['Email Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the text into a TF-IDF (Term Frequencey Inverse Document Frequency) matrix. This a statistical measure that evaluates how relevant a word is to a document in a collection of documents. It combines two metrics: the number of times a word appears in a document (term frequency) and the inverse document frequency of the word across the entire set of documents where each email is a document.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "The Email Type columns is then converted into a numpy array.  Data from both calculations is stored in a class object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert email text to an array of vectors, removing stop words\n",
    "tf = TfidfVectorizer(stop_words='english',max_features=10000) #dimension reduction\n",
    "feature_x = tf.fit_transform(df['Email Text']).toarray()\n",
    "\n",
    "# convert the label into numpy array\n",
    "y_tf = np.array(df['Email Type']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data science and traning and testing machine learning models, it is common practice to split the data into traning and validation splits.  Usually this is an 80/20 split where 80% of the data is used for training the model, and 20% is used for validation. The validation process is used to measure the accuracy of the model using various statistical measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training and testing data groups, 80 percent training, 20 percent testing\n",
    "X_tr,X_tst,y_tr,y_tst = train_test_split(feature_x,y_tf,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Now that we have split our data into traning and validation sets, we are ready for our first machine learning model that will be able to tell if an email is phishing or not based on the text of the email.  The first model we will explore is the SciKit implementation of [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "Logistic regression is a statistical method used for binary classification, where the goal is to predict the probability that a given input belongs to one of two categories. It models the relationship between a dependent binary variable and one or more independent variables using the logistic function, producing an output between 0 and 1. This output can then be thresholded to classify the input into one of the two categories.\n",
    "\n",
    "A good explanation of how this works can be found from the good folks at StatQuest:\n",
    "\n",
    "https://www.youtube.com/watch?v=yIYKR4sgzI8\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit data to model\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_tr,y_tr)\n",
    "\n",
    "pred_lg = lg.predict(X_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Explanation\n",
    "\n",
    "**Confusion Matrix**\n",
    "\n",
    "A confusion matrix is a tabular representation of the performance of a classification model, summarizing the predictions it made against the actual labels. It consists of four key values—True Positives, True Negatives, False Positives, and False Negatives—providing insight into the model’s accuracy, precision, recall, and other metrics.\n",
    "\n",
    "- upper left - number of emails predicted to be phishing and are actually phishing (True Positive)\n",
    "\n",
    "- upper right - number of emails predicted as not phishing that are actually phishing (False Positive)\n",
    "\n",
    "- lower left - number emails predicted to be phishing that are actually not phishing (False Negative)\n",
    "\n",
    "- lower right - number of emails predicted ast not phishing that are actually not phishing (True Negative)\n",
    "\n",
    "**Accuracy**\n",
    "\n",
    "Accuracy measures the proportion of correctly classified instances (both true positives and true negatives) out of the total number of instances. It provides a simple metric to evaluate a classification model's performance, especially when the dataset is balanced.\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{True Positives (TP)} + \\text{True Negatives (TN)}}{\\text{Total Instances (TP + TN + FP + FN)}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Precision**  \n",
    "Precision measures the proportion of correctly predicted positive instances out of all instances predicted as positive. It evaluates how precise or accurate the positive predictions are:  \n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Positives (FP)}}\n",
    "$$\n",
    "\n",
    "**Recall**  \n",
    "Recall (also called sensitivity or true positive rate) measures the proportion of actual positive instances that were correctly predicted by the model. It reflects the model’s ability to identify positive cases:  \n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\n",
    "$$\n",
    "\n",
    "**F1-Score**  \n",
    "The F1-score is the harmonic mean of precision and recall, providing a balanced metric that considers both false positives and false negatives. It is particularly useful when there is an imbalance between classes:  \n",
    "\n",
    "$$\n",
    "\\text{F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "**Support**  \n",
    "Support refers to the number of actual occurrences of each class in the dataset. It provides context for the performance metrics by showing how many instances were used to calculate them.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caclulate metrics Logistic Regression model.\n",
    "\n",
    "lr_accu = accuracy_score(y_tst,pred_lg)*100\n",
    "lr_f1 = f1_score(y_tst,pred_lg)*100\n",
    "\n",
    "print(\"The Logistic Regression model accuracy score was \" + str(lr_accu) + \"\\n\")\n",
    "print(\"The Logistic Regression model F1 score was \" + str(lr_f1) + \"\\n\")\n",
    "\n",
    "print(classification_report(y_tst,pred_lg))\n",
    "\n",
    "clf_lg = confusion_matrix(y_tst,pred_lg)\n",
    "cx_ = ConfusionMatrixDisplay(clf_lg,display_labels=['phishing_mail','safe_mail']).plot()\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "\n",
    "A [**Support Vector Machine (SVM)**](https://scikit-learn.org/stable/modules/svm.html#classification) is a supervised learning algorithm that is particularly effective for binary classification tasks. SVM works by finding the optimal hyperplane that best separates the data into two classes. The algorithm seeks to maximize the margin, which is the distance between the hyperplane and the nearest data points from each class, known as **support vectors**. This maximization improves the model's ability to generalize to unseen data. For non-linearly separable data, SVM uses a technique called the **kernel trick** to transform the input data into a higher-dimensional space, making it possible to find a linear separation. SVM is well-suited for text classification problems, as it performs effectively in high-dimensional spaces like those generated by text features (e.g., word frequencies or TF-IDF vectors).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit data to model\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_tr,y_tr)\n",
    "\n",
    "pred_svm = svm.predict(X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caclulate metrics Logistic Regression model.\n",
    "svm_accu = accuracy_score(y_tst,pred_svm)*100\n",
    "svm_f1 = f1_score(y_tst,pred_svm)*100\n",
    "\n",
    "\n",
    "print(\"The SVM model accuracy score was \" + str(svm_accu) + \"\\n\")\n",
    "print(\"The SVM model F1 score was \" + str(svm_f1) + \"\\n\")\n",
    "\n",
    "print(classification_report(y_tst,pred_svm))\n",
    "\n",
    "clf_lg = confusion_matrix(y_tst,pred_svm)\n",
    "cx_ = ConfusionMatrixDisplay(clf_lg,display_labels=['phishing_mail','safe_mail']).plot()\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes\n",
    "\n",
    "[**Multinomial Naive Bayes**](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#:~:text=The%20multinomial%20Naive%20Bayes%20classifier,tf%2Didf%20may%20also%20work.) is a probabilistic algorithm commonly used for text classification tasks. It is based on [**Bayes' Theorem**](https://www.youtube.com/watch?app=desktop&v=9wCnvr7Xw4E&t=0s), which calculates the posterior probability of a class given the observed features. The \"multinomial\" aspect refers to the assumption that the features (e.g., word counts or term frequencies) follow a multinomial distribution. Multinomial Naive Bayes works by estimating the likelihood of each word in the vocabulary given a class and combining these probabilities to classify the text. It assumes conditional independence between features, which simplifies computation and allows it to perform well on large datasets. This algorithm is particularly effective in applications with discrete features, making it a popular choice for email filtering and other text-based classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit data to model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metrics\n",
    "pred_nb = nb.predict(X_tst)\n",
    "nb_accu = accuracy_score(y_tst,pred_nb)*100\n",
    "nb_f1 = f1_score(y_tst,pred_nb)*100\n",
    "\n",
    "print(\"The Naive Bayes model accuracy score was \" + str(nb_accu) + \"\\n\")\n",
    "print(\"The Maive Bayes model F1 score was \" + str(nb_f1) + \"\\n\")\n",
    "\n",
    "print(classification_report(y_tst,pred_nb))\n",
    "\n",
    "clf_nb = confusion_matrix(y_tst,pred_nb)\n",
    "cx_ = ConfusionMatrixDisplay(clf_nb,display_labels=['phishing_mail','safe_mail']).plot()\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "upper left - number of emails predicted to be phishing and are actually phishing (True Positive)\n",
    "upper right - number of emails predicted as not phishing that are actually phishing (False Positive)\n",
    "lower left - number emails predicted to be phishing that are actually not phishing (False Negative)\n",
    "lower right - number of emails predicted ast not phishing that are actually not phishing (True Negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "A [**Decision Tree**](https://scikit-learn.org/1.5/modules/tree.html) is a supervised learning algorithm that is commonly used for both classification and regression tasks. For a spam vs. ham classification problem, the decision tree works by recursively splitting the dataset based on feature values to create a tree-like structure of decisions. Each internal node in the tree represents a feature test (e.g., \"Does the email contain the word 'free'?\"), each branch represents the outcome of the test, and each leaf node represents the predicted class (spam or ham). The splits are chosen to maximize the homogeneity of the data within each subset, often using metrics like **Gini Impurity** or **Information Gain**. Decision trees are intuitive, easy to visualize, and handle both numerical and categorical data, making them a strong baseline algorithm for text classification tasks like email filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit data to model\n",
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metrics\n",
    "pred_dt = dt.predict(X_tst)\n",
    "dt_accu = accuracy_score(y_tst,pred_dt)*100\n",
    "dt_f1 = f1_score(y_tst,pred_dt)*100\n",
    "\n",
    "print(\"The Decision Tree model accuracy score was \" + str(dt_accu) + \"\\n\")\n",
    "print(\"The Decision Tree model F1 score was \" + str(dt_f1) + \"\\n\")\n",
    "\n",
    "print(classification_report(y_tst,pred_dt))\n",
    "\n",
    "clf_dt = confusion_matrix(y_tst,pred_dt)\n",
    "cx_ = ConfusionMatrixDisplay(clf_dt,display_labels=['phishing_mail','safe_mail']).plot()\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "A [**Random Forest**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) is an ensemble learning algorithm that combines multiple decision trees to improve classification accuracy and reduce the risk of overfitting. In the context of classifying emails as spam or ham, the algorithm builds multiple decision trees during training, with each tree trained on a random subset of the data and features. The final prediction is determined by aggregating the predictions of all the trees, often through majority voting. This randomness in both data and features introduces diversity among the trees, making the model more robust to noise and better at generalizing to unseen data. Random Forests are particularly effective for high-dimensional datasets like text classification, as they can handle the complexities of features like word frequencies or TF-IDF scores while maintaining good performance and interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = rf.predict(X_tst)\n",
    "rf_accu = accuracy_score(y_tst,pred_rf)*100\n",
    "rf_f1 = f1_score(y_tst,pred_rf)*100\n",
    "\n",
    "print(\"The Random Forest model accuracy score was \" + str(rf_accu) + \"\\n\")\n",
    "print(\"The Random Forest model F1 score was \" + str(rf_f1) + \"\\n\")\n",
    "\n",
    "print(classification_report(y_tst,pred_rf))\n",
    "\n",
    "clf_rf = confusion_matrix(y_tst,pred_rf)\n",
    "cx_ = ConfusionMatrixDisplay(clf_rf,display_labels=['phishing_mail','safe_mail']).plot()\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table of models and comparisons\n",
    "\n",
    "accu_values = [lr_accu,svm_accu,nb_accu,dt_accu,rf_accu]\n",
    "row_labels = [\"Logistic Regression\", \"SVM\", \"Naive Bayes\",\"Decision Tree\",\"Random Forest\"]\n",
    "comp_df = pd.DataFrame(accu_values, columns=[\"accuracy\"], index=row_labels)\n",
    "print(comp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Challenge Exercise\n",
    "\n",
    "There is another Scikit Learn supervised learning method called Gradient Boosting Machine (GBM) that could potentially be used as a binary classifier for our phishing data. Your challenge is to use the code above as a template and fit the data to a GBM model.  Is the accuracy better or worse than our previous models?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
